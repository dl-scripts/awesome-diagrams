schema-version: 0.1
# Required
name: LocalAI Architecture
images:
  - 1.png
attribution: https://localai.io/docs/reference/architecture/
tags:
  - go
  - ai
# Optional
author: Ettore Di Giacinto
description: |
  LocalAI is an API written in Go that serves as an OpenAI shim, enabling software already developed with OpenAI SDKs to seamlessly integrate with LocalAI. It can be effortlessly implemented as a substitute, even on consumer-grade hardware. This capability is achieved by employing various C++ backends, including ggml, to perform inference on LLMs using both CPU and, if desired, GPU. Internally LocalAI backends are just gRPC server, indeed you can specify and build your own gRPC server and extend LocalAI in runtime as well. It is possible to specify external gRPC server and/or binaries that LocalAI will manage internally.
